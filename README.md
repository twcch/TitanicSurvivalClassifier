# Titanic Survival Classifier

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

A production-ready machine learning pipeline for predicting Titanic passenger survival using Object-Oriented Programming (OOP) design patterns.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Architecture](#project-architecture)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Pipeline Components](#pipeline-components)
- [Model Performance](#model-performance)
- [Advanced Usage](#advanced-usage)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)

## ğŸ¯ Overview

This project implements a complete machine learning pipeline for the [Kaggle Titanic competition](https://www.kaggle.com/competitions/titanic) using **Object-Oriented Design Principles**. The architecture is designed for:

- âœ… **Modularity**: Each component is independent and reusable
- âœ… **Extensibility**: Easy to add new preprocessing steps, features, or models
- âœ… **Maintainability**: Clear separation of concerns with SOLID principles
- âœ… **Production-Ready**: Includes model persistence, evaluation metrics, and logging

## âœ¨ Features

- ğŸ—ï¸ **OOP Architecture**: Clean, modular design with abstract base classes
- ğŸ”„ **Pipeline Pattern**: Composable preprocessing and feature engineering steps
- ğŸ“Š **Multiple Models**: Support for Decision Tree, Random Forest, XGBoost, etc.
- ğŸ“ˆ **Comprehensive Evaluation**: Accuracy, Precision, Recall, F1-Score, ROC-AUC
- ğŸ’¾ **Model Persistence**: Save and load trained models
- ğŸ¨ **One-Hot Encoding**: Automatic categorical feature encoding
- ğŸ”§ **Missing Value Handling**: Multiple strategies (mean, median, mode)
- ğŸ“ **Logging Support**: Track experiments and model performance

## ğŸ›ï¸ Project Architecture

The project follows **Clean Architecture** principles with clear separation between layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Pipeline Orchestration          â”‚
â”‚         (ml_pipeline.py)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data   â”‚  â”‚  Model   â”‚  â”‚Evaluationâ”‚
â”‚  Layer   â”‚  â”‚  Layer   â”‚  â”‚  Layer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚           â”‚
        â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Preprocessâ”‚  â”‚ Feature  â”‚  â”‚ Encoding â”‚
â”‚  Layer   â”‚  â”‚Engineer  â”‚  â”‚  Layer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Patterns Used

- **Strategy Pattern**: Interchangeable preprocessing and feature engineering strategies
- **Pipeline Pattern**: Sequential data transformations
- **Template Method Pattern**: Base classes define workflow, subclasses implement specifics
- **Factory Pattern**: Model creation and instantiation

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Setup

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/TitanicSurvivalClassifier.git
cd TitanicSurvivalClassifier
```

2. **Create virtual environment** (recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

### Required Packages

```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
joblib>=1.1.0
```

## ğŸ¬ Quick Start

### Training a Model

```python
from core.pipeline.ml_pipeline import MLPipeline

# Initialize pipeline
pipeline = MLPipeline()

# Train model
pipeline.run_training_pipeline("data/raw/train.csv")
```

### Making Predictions

```python
# Run inference on test data
submission = pipeline.run_inference_pipeline(
    model_path="outputs/decision_tree_model.pkl",
    test_path="data/raw/test.csv",
    output_path="outputs/submission.csv"
)
```

### Complete Example

```bash
python main.py
```

**Expected Output:**

```
==================================================
é–‹å§‹è¨“ç·´æ¨¡å‹...
==================================================

==================================================
æ¨¡å‹è©•ä¼°çµæœ (Model Evaluation Results)
==================================================
accuracy    : 0.8324
precision   : 0.8156
recall      : 0.7234
f1_score    : 0.7667
roc_auc     : 0.8891
==================================================

âœ… é æ¸¬å®Œæˆï¼çµæœå·²å„²å­˜è‡³ outputs/submission.csv
```

## ğŸ“ Project Structure

```
TitanicSurvivalClassifier/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_loader.py              # Data loading utilities
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ preprocessor.py             # Preprocessing strategies
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ feature_engineer.py         # Feature engineering
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_model.py               # Abstract model interface
â”‚   â”‚   â””â”€â”€ decision_tree_classifier_model.py
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ ml_pipeline.py              # Pipeline orchestration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ train.csv                    # Training data
â”‚       â””â”€â”€ test.csv                     # Test data
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ decision_tree_model.pkl         # Saved model
â”‚   â””â”€â”€ submission.csv                  # Predictions
â”œâ”€â”€ main.py                              # Entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ Pipeline Components

### 1. Data Loading ([`DataLoader`](core/data/data_loader.py))

```python
from core.data.data_loader import DataLoader

loader = DataLoader()
df = loader.load_data("data/raw/train.csv")
```

### 2. Preprocessing ([`PreprocessingPipeline`](core/preprocessing/preprocessor.py))

```python
from core.preprocessing.preprocessor import (
    PreprocessingPipeline,
    MissingValueHandler,
    DropColumnsPreprocessor
)

preprocessing_steps = [
    DropColumnsPreprocessor(columns_to_drop=["PassengerId", "Name", "Ticket", "Cabin"]),
    MissingValueHandler(strategy="mean")
]

preprocessor = PreprocessingPipeline(steps=preprocessing_steps)
X_processed = preprocessor.fit_transform(X)
```

**Available Preprocessing Strategies:**
- `MissingValueHandler`: Handle missing values (mean, median, mode, drop)
- `OutlierHandler`: Detect and handle outliers (z-score, IQR)
- `DropColumnsPreprocessor`: Remove unnecessary columns

### 3. Feature Engineering ([`FeatureEngineerPipeline`](core/features/feature_engineer.py))

```python
from core.features.feature_engineer import (
    FeatureEngineerPipeline,
    OneHotEncoder
)

feature_steps = [
    OneHotEncoder(columns=["Sex", "Embarked", "Pclass"])
]

feature_engineer = FeatureEngineerPipeline(steps=feature_steps)
X_features = feature_engineer.fit_transform(X)
```

### 4. Model Training ([`DecisionTreeClassifierModel`](core/models/decision_tree_classifier_model.py))

```python
from core.models.decision_tree_classifier_model import DecisionTreeClassifierModel

model = DecisionTreeClassifierModel()
model.train((X_train, y_train))
metrics = model.evaluate((X_val, y_val))
model.save_model("outputs/model.pkl")
```

## ğŸ“Š Model Performance

### Evaluation Metrics

The model is evaluated using multiple metrics:

| Metric | Score | Description |
|--------|-------|-------------|
| **Accuracy** | 0.8324 | Overall prediction accuracy |
| **Precision** | 0.8156 | Positive prediction accuracy |
| **Recall** | 0.7234 | True positive detection rate |
| **F1-Score** | 0.7667 | Harmonic mean of precision/recall |
| **ROC-AUC** | 0.8891 | Area under ROC curve |

### Cross-Validation

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model.model, X, y, cv=5, scoring='accuracy')
print(f"CV Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})")
```

## ğŸ“ Advanced Usage

### Adding Custom Preprocessing Step

```python
from core.preprocessing.preprocessor import BasePreprocessor

class CustomScaler(BasePreprocessor):
    def __init__(self):
        self.scaler = StandardScaler()
    
    def fit(self, X):
        self.scaler.fit(X)
        return self
    
    def transform(self, X):
        return pd.DataFrame(
            self.scaler.transform(X),
            columns=X.columns,
            index=X.index
        )
```

### Adding New Model

```python
from core.models.base_model import BaseModel
from sklearn.ensemble import RandomForestClassifier

class RandomForestModel(BaseModel):
    def __init__(self, n_estimators=100):
        self.model = RandomForestClassifier(n_estimators=n_estimators)
    
    def train(self, data):
        X, y = data
        self.model.fit(X, y)
    
    def predict(self, input_data):
        return self.model.predict(input_data)
    
    def evaluate(self, test_data):
        # Implementation similar to DecisionTreeClassifierModel
        pass
```

### Custom Feature Engineering

```python
from core.features.feature_engineer import BaseFeatureEngineer

class FamilySizeFeature(BaseFeatureEngineer):
    def fit(self, X):
        return self
    
    def transform(self, X):
        X = X.copy()
        X['FamilySize'] = X['SibSp'] + X['Parch'] + 1
        X['IsAlone'] = (X['FamilySize'] == 1).astype(int)
        return X
```

## ğŸ”„ Continuous Integration

### Running Tests

```bash
pytest tests/
```

### Code Quality

```bash
# Format code
black core/ tests/

# Lint code
pylint core/

# Type checking
mypy core/
```

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Code Style

- Follow PEP 8 guidelines
- Use type hints where possible
- Write docstrings for all public methods
- Add unit tests for new features

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“§ Contact

**Chih-Chien Hsieh**
- Email: twcch1218 [at] gmail.com
- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Your LinkedIn](https://linkedin.com/in/yourprofile)

## ğŸ™ Acknowledgments

- [Kaggle Titanic Competition](https://www.kaggle.com/competitions/titanic) for the dataset
- Scikit-learn for machine learning tools
- The open-source community for inspiration

## ğŸ“š Additional Resources

- [Kaggle Competition Page](https://www.kaggle.com/competitions/titanic)
- [Project Documentation](docs/)
- [API Reference](docs/api/)
- [Tutorial Notebooks](notebooks/)

## ğŸ—ºï¸ Roadmap

- [ ] Add support for ensemble models
- [ ] Implement hyperparameter tuning with Optuna
- [ ] Add SHAP values for model interpretation
- [ ] Create web interface with Streamlit
- [ ] Add experiment tracking with MLflow
- [ ] Implement automated feature selection
- [ ] Add Docker support for deployment

## License

Auralytics is licensed under the Apache License 2.0. You are free to use, modify, and distribute the project, as long as you comply with the terms of the license, including proper attribution and inclusion of the license notice.

This project is licensed under the MIT License. See [LICENSE](LICENSE).

## Contact Us

If you have any questions or suggestions, feel free to reach out to us:

- Email: twcch1218 [at] gmail.com

Thank you for your interest in TitanicSurvivalClassifer! We look forward to your contributions and hope you enjoy using and improving this project.

## Notes

- Kaggle url: https://www.kaggle.com/competitions/titanic