import pandas as pd
import os
from datetime import datetime
from pathlib import Path
from core.data.data_loader import DataLoader
from core.preprocessing.preprocessor import (
    PreprocessingPipeline,
    MissingValueHandler,
    DropColumnsPreprocessor,
)
from core.features.feature_engineer import (
    FeatureEngineerPipeline,
    OneHotEncoder,
)
from core.models.decision_tree_classifier_model import DecisionTreeClassifierModel
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split


class MLPipeline:
    def __init__(self, use_tuning: bool = True, tuning_method: str = "grid"):
        self.data_loader = DataLoader()

        preprocessing_steps = [
            # å…ˆç§»é™¤ä¸éœ€è¦çš„æ¬„ä½
            DropColumnsPreprocessor(
                columns_to_drop=["PassengerId", "Name", "Ticket", "Cabin"]
            ),
            MissingValueHandler(strategy="mean"),
        ]

        self.preprocessing_pipeline = PreprocessingPipeline(steps=preprocessing_steps)

        feature_engineering_steps = [
            OneHotEncoder(columns=["Sex", "Embarked", "Pclass"]),
        ]

        self.feature_engineer_pipeline = FeatureEngineerPipeline(
            steps=feature_engineering_steps
        )

        self.model = DecisionTreeClassifierModel(
            use_tuning=use_tuning, tuning_method=tuning_method, cv=5
        )

        # ç”Ÿæˆå”¯ä¸€çš„å¯¦é©—è³‡æ–™å¤¾åç¨±
        self.experiment_dir = self._create_experiment_dir()

    def _create_experiment_dir(self) -> str:
        """
        å»ºç«‹å”¯ä¸€çš„å¯¦é©—è³‡æ–™å¤¾
        æ ¼å¼: results_YYYYMMDDHHMMSS_xxx_N
        xxx: æ¯«ç§’
        N: æµæ°´åºè™Ÿ

        Returns:
            str: å¯¦é©—è³‡æ–™å¤¾è·¯å¾‘
        """
        base_dir = Path("outputs")
        base_dir.mkdir(exist_ok=True)

        # ç”Ÿæˆæ™‚é–“æˆ³è¨˜ (å«æ¯«ç§’)
        now = datetime.now()
        timestamp = now.strftime("%Y%m%d%H%M%S")
        milliseconds = now.strftime("%f")[:3]  # å–å‰ä¸‰ä½æ¯«ç§’

        # æ‰¾å‡ºåŒä¸€ç§’å…§çš„æµæ°´åºè™Ÿ
        sequence = 0
        while True:
            dir_name = f"results_{timestamp}{milliseconds}{sequence}"
            experiment_path = base_dir / dir_name

            if not experiment_path.exists():
                experiment_path.mkdir(parents=True)
                print(f"\nğŸ“ å»ºç«‹å¯¦é©—è³‡æ–™å¤¾: {experiment_path}")
                return str(experiment_path)

            sequence += 1

    def run_training_pipeline(self, train_path: str):
        """
        åŸ·è¡Œè¨“ç·´æµç¨‹

        Args:
            train_path: è¨“ç·´è³‡æ–™è·¯å¾‘
        """
        df = self.data_loader.load_data(train_path)

        y = df["Survived"]
        X = df.drop(columns=["Survived"])

        X = self.preprocessing_pipeline.fit_transform(X)
        X = self.feature_engineer_pipeline.fit_transform(X)

        # 4. åˆ†å‰²è¨“ç·´é›†èˆ‡é©—è­‰é›†
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # 5. è¨“ç·´æ¨¡å‹
        self.model.train((X_train, y_train))

        # 6. è©•ä¼°æ¨¡å‹
        metrics = self.model.evaluate((X_val, y_val))

        # 7. å°å‡ºè©•ä¼°çµæœ
        print("\n" + "=" * 50)
        print("æ¨¡å‹è©•ä¼°çµæœ (Model Evaluation Results)")
        print("=" * 50)
        for metric_name, metric_value in metrics.items():
            print(f"{metric_name:12s}: {metric_value:.4f}")
        print("=" * 50 + "\n")

        print("ä½¿ç”¨æœ€ä½³åƒæ•¸åœ¨å…¨éƒ¨è³‡æ–™ä¸Šé‡æ–°è¨“ç·´...")
        # å»ºç«‹æ–°æ¨¡å‹ä½¿ç”¨æœ€ä½³åƒæ•¸
        if self.model.best_params:
            best_model = DecisionTreeClassifier(**self.model.best_params)
            best_model.fit(X, y)
            self.model.model = best_model
            if hasattr(X, "columns"):
                self.model.feature_names = X.columns.tolist()
        else:
            self.model.train((X, y))

        # 8. å„²å­˜æ¨¡å‹åˆ°å¯¦é©—è³‡æ–™å¤¾
        model_path = os.path.join(self.experiment_dir, "decision_tree_model.pkl")
        self.model.save_model(model_path)
        print(f"âœ… æ¨¡å‹å·²å„²å­˜è‡³ {model_path}")

        # 9. è¦–è¦ºåŒ–æ±ºç­–æ¨¹
        print("\n" + "=" * 50)
        print("ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")
        print("=" * 50)
        tree_path = os.path.join(self.experiment_dir, "decision_tree.png")
        importance_path = os.path.join(self.experiment_dir, "feature_importance.png")

        self.model.visualize_tree(tree_path)
        self.model.visualize_feature_importance(importance_path)

        # 10. å°å‡ºç‰¹å¾µé‡è¦æ€§
        importance = self.model.get_feature_importance(top_n=10)
        if importance:
            print("\nç‰¹å¾µé‡è¦æ€§ (Top 10):")
            print("-" * 50)
            for i, (feature, score) in enumerate(importance.items(), 1):
                print(f"{i:2d}. {feature:30s}: {score:.4f}")
            print("=" * 50 + "\n")

        # 11. å„²å­˜å¯¦é©—å ±å‘Š
        self._save_experiment_report(metrics, importance)

        return metrics

    def run_inference_pipeline(
        self, model_path: str, test_path: str, output_path: str = None
    ):
        """
        åŸ·è¡Œæ¨è«–æµç¨‹

        Args:
            model_path: æ¨¡å‹è·¯å¾‘ï¼ˆå¦‚æœæ˜¯ç›¸å°è·¯å¾‘ï¼Œæœƒåœ¨å¯¦é©—è³‡æ–™å¤¾ä¸­å°‹æ‰¾ï¼‰
            test_path: æ¸¬è©¦è³‡æ–™è·¯å¾‘
            output_path: è¼¸å‡ºè·¯å¾‘ï¼ˆå¦‚æœç‚º Noneï¼Œæœƒè‡ªå‹•åœ¨å¯¦é©—è³‡æ–™å¤¾ä¸­ç”Ÿæˆï¼‰
        """
        # å¦‚æœæ²’æœ‰æŒ‡å®šè¼¸å‡ºè·¯å¾‘ï¼Œä½¿ç”¨å¯¦é©—è³‡æ–™å¤¾
        if output_path is None:
            output_path = os.path.join(self.experiment_dir, "submission.csv")

        # è¼‰å…¥æ¸¬è©¦è³‡æ–™
        df = self.data_loader.load_data(test_path)

        # ä¿å­˜ PassengerId
        passenger_ids = df["PassengerId"].copy()

        # ç§»é™¤ PassengerId é€²è¡Œé æ¸¬
        if "PassengerId" in df.columns:
            df = df.drop(columns=["PassengerId"])

        # å‰è™•ç†å’Œç‰¹å¾µå·¥ç¨‹
        df = self.preprocessing_pipeline.transform(df)
        df = self.feature_engineer_pipeline.transform(df)

        # è¼‰å…¥æ¨¡å‹ä¸¦é æ¸¬
        self.model.load_model(model_path)
        predictions = self.model.predict(df)

        # å»ºç«‹æäº¤æª”æ¡ˆ
        submission = pd.DataFrame(
            {"PassengerId": passenger_ids, "Survived": predictions}
        )

        # å„²å­˜çµæœ
        submission.to_csv(output_path, index=False)
        print(f"\nâœ… é æ¸¬å®Œæˆï¼çµæœå·²å„²å­˜è‡³ {output_path}")
        print(f"\né æ¸¬çµæœå‰ 10 ç­†ï¼š")
        print(submission.head(10))
        print(f"\nç¸½å…±é æ¸¬ {len(submission)} ç­†è³‡æ–™")
        print(f"é æ¸¬å­˜æ´»äººæ•¸: {submission['Survived'].sum()}")
        print(f"é æ¸¬æ­»äº¡äººæ•¸: {(submission['Survived'] == 0).sum()}")

        return submission

    def _save_experiment_report(self, metrics: dict, feature_importance: dict):
        """
        å„²å­˜å¯¦é©—å ±å‘Š

        Args:
            metrics: è©•ä¼°æŒ‡æ¨™
            feature_importance: ç‰¹å¾µé‡è¦æ€§
        """
        report_path = os.path.join(self.experiment_dir, "experiment_report.txt")

        with open(report_path, "w", encoding="utf-8") as f:
            f.write("=" * 60 + "\n")
            f.write("å¯¦é©—å ±å‘Š (Experiment Report)\n")
            f.write("=" * 60 + "\n\n")

            # å¯¦é©—è³‡è¨Š
            f.write(f"å¯¦é©—æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å¯¦é©—è³‡æ–™å¤¾: {self.experiment_dir}\n\n")

            # æ¨¡å‹è¨­å®š
            f.write("-" * 60 + "\n")
            f.write("æ¨¡å‹è¨­å®š\n")
            f.write("-" * 60 + "\n")
            f.write(f"ä½¿ç”¨è¶…åƒæ•¸èª¿å„ª: {self.model.use_tuning}\n")
            if self.model.use_tuning:
                f.write(f"èª¿å„ªæ–¹æ³•: {self.model.tuning_method}\n")
                f.write(f"äº¤å‰é©—è­‰æŠ˜æ•¸: {self.model.cv}\n")
            f.write("\n")

            # æœ€ä½³åƒæ•¸
            if self.model.best_params:
                f.write("-" * 60 + "\n")
                f.write("æœ€ä½³è¶…åƒæ•¸\n")
                f.write("-" * 60 + "\n")
                for param, value in self.model.best_params.items():
                    f.write(f"  {param:30s}: {value}\n")
                f.write("\n")

            # è©•ä¼°æŒ‡æ¨™
            f.write("-" * 60 + "\n")
            f.write("æ¨¡å‹è©•ä¼°çµæœ\n")
            f.write("-" * 60 + "\n")
            for metric_name, metric_value in metrics.items():
                f.write(f"  {metric_name:15s}: {metric_value:.4f}\n")
            f.write("\n")

            # ç‰¹å¾µé‡è¦æ€§
            if feature_importance:
                f.write("-" * 60 + "\n")
                f.write("ç‰¹å¾µé‡è¦æ€§ (Top 10)\n")
                f.write("-" * 60 + "\n")
                for i, (feature, score) in enumerate(feature_importance.items(), 1):
                    f.write(f"  {i:2d}. {feature:35s}: {score:.4f}\n")
                f.write("\n")

            f.write("=" * 60 + "\n")

        print(f"âœ… å¯¦é©—å ±å‘Šå·²å„²å­˜è‡³ {report_path}")
