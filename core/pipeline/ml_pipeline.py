import pandas as pd
import os
from datetime import datetime
from pathlib import Path
from core.data.data_loader import DataLoader
from core.preprocessing.preprocessor import (
    PreprocessingPipeline,
    MissingValueHandler,
    DropColumnsPreprocessor,
)
from core.features.feature_engineer import (
    FeatureEngineerPipeline,
    OneHotEncoder,
)
from core.models.model_factory import ModelFactory
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.model_selection import train_test_split


class MLPipeline:
    def __init__(
        self,
        model_type: str = "decision_tree",
        use_tuning: bool = True,
        tuning_method: str = "grid",
    ):
        """
        åˆå§‹åŒ– ML Pipeline

        Args:
            model_type: æ¨¡å‹é¡å‹ ("decision_tree", "random_forest", "xgboost", ç­‰)
            use_tuning: æ˜¯å¦ä½¿ç”¨è¶…åƒæ•¸èª¿å„ª
            tuning_method: èª¿å„ªæ–¹æ³• ("grid" æˆ– "random")
        """
        self.model_type = model_type
        self.data_loader = DataLoader()

        preprocessing_steps = [
            DropColumnsPreprocessor(
                columns_to_drop=["PassengerId", "Name", "Ticket", "Cabin"]
            ),
            MissingValueHandler(strategy="mean"),
        ]

        self.preprocessing_pipeline = PreprocessingPipeline(steps=preprocessing_steps)

        feature_engineering_steps = [
            OneHotEncoder(columns=["Sex", "Embarked", "Pclass"]),
        ]

        self.feature_engineer_pipeline = FeatureEngineerPipeline(
            steps=feature_engineering_steps
        )

        # ä½¿ç”¨å·¥å» æ¨¡å¼å‰µå»ºæ¨¡å‹
        self.model = ModelFactory.create_model(
            model_type=model_type,
            use_tuning=use_tuning,
            tuning_method=tuning_method,
            cv=5,
        )

        # ç”Ÿæˆå”¯ä¸€çš„å¯¦é©—è³‡æ–™å¤¾åç¨±
        self.experiment_dir = self._create_experiment_dir()

    def _create_experiment_dir(self) -> str:
        """
        å»ºç«‹å”¯ä¸€çš„å¯¦é©—è³‡æ–™å¤¾
        æ ¼å¼: results_MODELTYPE_YYYYMMDDHHMMSS_xxx_N
        """
        base_dir = Path("outputs")
        base_dir.mkdir(exist_ok=True)

        now = datetime.now()
        timestamp = now.strftime("%Y%m%d%H%M%S")
        milliseconds = now.strftime("%f")[:3]

        sequence = 0
        while True:
            dir_name = f"results_{self.model_type}_{timestamp}{milliseconds}{sequence}"
            experiment_path = base_dir / dir_name

            if not experiment_path.exists():
                experiment_path.mkdir(parents=True)
                print(f"\nğŸ“ å»ºç«‹å¯¦é©—è³‡æ–™å¤¾: {experiment_path}")
                print(f"ğŸ“Š ä½¿ç”¨æ¨¡å‹: {self.model_type.upper()}")
                return str(experiment_path)

            sequence += 1

    def run_training_pipeline(self, train_path: str):
        """åŸ·è¡Œè¨“ç·´æµç¨‹"""
        df = self.data_loader.load_data(train_path)

        y = df["Survived"]
        X = df.drop(columns=["Survived"])

        X = self.preprocessing_pipeline.fit_transform(X)
        X = self.feature_engineer_pipeline.fit_transform(X)

        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # è¨“ç·´æ¨¡å‹
        self.model.train((X_train, y_train))

        # è©•ä¼°æ¨¡å‹
        metrics = self.model.evaluate((X_val, y_val))

        print("\n" + "=" * 50)
        print("æ¨¡å‹è©•ä¼°çµæœ (Model Evaluation Results)")
        print("=" * 50)
        for metric_name, metric_value in metrics.items():
            print(f"{metric_name:12s}: {metric_value:.4f}")
        print("=" * 50 + "\n")

        print("ä½¿ç”¨æœ€ä½³åƒæ•¸åœ¨å…¨éƒ¨è³‡æ–™ä¸Šé‡æ–°è¨“ç·´...")

        # æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡å°æ‡‰çš„é¡åˆ¥
        if self.model.best_params:
            if self.model_type == "decision_tree":
                best_model = DecisionTreeClassifier(**self.model.best_params)
            elif self.model_type == "random_forest":
                best_model = RandomForestClassifier(**self.model.best_params)
            elif self.model_type == "xgboost":
                best_model = xgb.XGBClassifier(**self.model.best_params)
            else:
                best_model = self.model.model.__class__(**self.model.best_params)

            best_model.fit(X, y)
            self.model.model = best_model
            if hasattr(X, "columns"):
                self.model.feature_names = X.columns.tolist()
        else:
            self.model.train((X, y))

        # å„²å­˜æ¨¡å‹
        model_filename = f"{self.model_type}_model.pkl"
        model_path = os.path.join(self.experiment_dir, model_filename)
        self.model.save_model(model_path)
        print(f"âœ… æ¨¡å‹å·²å„²å­˜è‡³ {model_path}")

        # è¦–è¦ºåŒ–
        print("\n" + "=" * 50)
        print("ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")
        print("=" * 50)

        tree_filename = f"{self.model_type}_visualization.png"
        tree_path = os.path.join(self.experiment_dir, tree_filename)
        importance_path = os.path.join(self.experiment_dir, "feature_importance.png")

        self.model.visualize_tree(tree_path)
        self.model.visualize_feature_importance(importance_path)
        
        # XGBoost é¡å¤–çš„è¦–è¦ºåŒ–
        if self.model_type == "xgboost":
            xgb_importance_path = os.path.join(
                self.experiment_dir, "xgboost_importance_plot.png"
            )
            self.model.plot_importance(xgb_importance_path)

        # ç‰¹å¾µé‡è¦æ€§
        importance = self.model.get_feature_importance(top_n=10)
        if importance:
            print("\nç‰¹å¾µé‡è¦æ€§ (Top 10):")
            print("-" * 50)
            for i, (feature, score) in enumerate(importance.items(), 1):
                print(f"{i:2d}. {feature:30s}: {score:.4f}")
            print("=" * 50 + "\n")

        # å„²å­˜å¯¦é©—å ±å‘Š
        self._save_experiment_report(metrics, importance)

        return metrics

    def run_inference_pipeline(
        self, model_path: str, test_path: str, output_path: str = None
    ):
        """åŸ·è¡Œæ¨è«–æµç¨‹"""
        if output_path is None:
            output_path = os.path.join(self.experiment_dir, "submission.csv")

        df = self.data_loader.load_data(test_path)
        passenger_ids = df["PassengerId"].copy()

        if "PassengerId" in df.columns:
            df = df.drop(columns=["PassengerId"])

        df = self.preprocessing_pipeline.transform(df)
        df = self.feature_engineer_pipeline.transform(df)

        self.model.load_model(model_path)
        predictions = self.model.predict(df)

        submission = pd.DataFrame(
            {"PassengerId": passenger_ids, "Survived": predictions}
        )

        submission.to_csv(output_path, index=False)
        print(f"\nâœ… é æ¸¬å®Œæˆï¼çµæœå·²å„²å­˜è‡³ {output_path}")
        print(f"\né æ¸¬çµæœå‰ 10 ç­†ï¼š")
        print(submission.head(10))
        print(f"\nç¸½å…±é æ¸¬ {len(submission)} ç­†è³‡æ–™")
        print(f"é æ¸¬å­˜æ´»äººæ•¸: {submission['Survived'].sum()}")
        print(f"é æ¸¬æ­»äº¡äººæ•¸: {(submission['Survived'] == 0).sum()}")

        return submission

    def _save_experiment_report(self, metrics: dict, feature_importance: dict):
        """å„²å­˜å¯¦é©—å ±å‘Š"""
        report_path = os.path.join(self.experiment_dir, "experiment_report.txt")

        with open(report_path, "w", encoding="utf-8") as f:
            f.write("=" * 60 + "\n")
            f.write("å¯¦é©—å ±å‘Š (Experiment Report)\n")
            f.write("=" * 60 + "\n\n")

            f.write(f"å¯¦é©—æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å¯¦é©—è³‡æ–™å¤¾: {self.experiment_dir}\n")
            f.write(f"æ¨¡å‹é¡å‹: {self.model_type.upper()}\n\n")

            f.write("-" * 60 + "\n")
            f.write("æ¨¡å‹è¨­å®š\n")
            f.write("-" * 60 + "\n")
            f.write(f"ä½¿ç”¨è¶…åƒæ•¸èª¿å„ª: {self.model.use_tuning}\n")
            if self.model.use_tuning:
                f.write(f"èª¿å„ªæ–¹æ³•: {self.model.tuning_method}\n")
                f.write(f"äº¤å‰é©—è­‰æŠ˜æ•¸: {self.model.cv}\n")
            f.write("\n")

            if self.model.best_params:
                f.write("-" * 60 + "\n")
                f.write("æœ€ä½³è¶…åƒæ•¸\n")
                f.write("-" * 60 + "\n")
                for param, value in self.model.best_params.items():
                    f.write(f"  {param:30s}: {value}\n")
                f.write("\n")

            f.write("-" * 60 + "\n")
            f.write("æ¨¡å‹è©•ä¼°çµæœ\n")
            f.write("-" * 60 + "\n")
            for metric_name, metric_value in metrics.items():
                f.write(f"  {metric_name:15s}: {metric_value:.4f}\n")
            f.write("\n")

            if feature_importance:
                f.write("-" * 60 + "\n")
                f.write("ç‰¹å¾µé‡è¦æ€§ (Top 10)\n")
                f.write("-" * 60 + "\n")
                for i, (feature, score) in enumerate(feature_importance.items(), 1):
                    f.write(f"  {i:2d}. {feature:35s}: {score:.4f}\n")
                f.write("\n")

            f.write("=" * 60 + "\n")

        print(f"âœ… å¯¦é©—å ±å‘Šå·²å„²å­˜è‡³ {report_path}")